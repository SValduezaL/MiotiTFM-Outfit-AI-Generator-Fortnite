# Fine-tuning de Modelo Base para Generaci√≥n de Outfits Fortnite - TFM Skin AI Gen Fortnite

## üìã Overview del Proyecto

Este documento describe el proceso de fine-tuning del modelo base Stable Diffusion XL (SDXL) sobre datos de Fortnite para establecer la base estil√≠stica necesaria para la generaci√≥n de outfits. Este fine-tuning constituye la primera etapa del pipeline, previa al entrenamiento de LoRAs especializados.

### Contexto Acad√©mico

**Problema abordado:** Establecer una base estil√≠stica coherente que capture las caracter√≠sticas visuales distintivas de Fortnite (proporciones, iluminaci√≥n, texturas, anatom√≠a) mediante fine-tuning completo del modelo base SDXL.

**Soluci√≥n propuesta:** Fine-tuning del modelo completo SDXL Base 1.0 sobre un dataset curado de im√°genes de personajes de Fortnite, seguido de iteraciones experimentales para optimizar hiperpar√°metros y lograr el balance √≥ptimo entre fidelidad al estilo Fortnite y capacidad de generalizaci√≥n.

---

## üèóÔ∏è Arquitectura y Enfoque

### Modelo Base

El fine-tuning se realiz√≥ sobre **Stable Diffusion XL Base 1.0** (`sd_xl_base_1.0.safetensors`), modelo generativo de difusi√≥n desarrollado por Stability AI.

**Justificaci√≥n del enfoque:**

1. **Fine-tuning completo vs. LoRA:** A diferencia de los LoRAs especializados posteriores, el fine-tuning completo modifica todos los pesos del modelo, estableciendo una base estil√≠stica profunda que afecta todas las generaciones subsiguientes.
2. **Base para especializaci√≥n:** Este modelo fine-tuned (`humanoid_05`) sirve como base para todos los LoRAs especializados, permitiendo que estos se enfoquen en variaciones tem√°ticas sin perder la identidad visual de Fortnite.
3. **Ventajas t√©cnicas:**
    - **Coherencia estil√≠stica:** El modelo base aprende caracter√≠sticas generales del arte de Fortnite
    - **Preservaci√≥n de capacidades:** Mantiene la capacidad de generar personajes humanos est√°ndar
    - **Base estable:** Proporciona una base s√≥lida para entrenamientos LoRA posteriores

### Rol de KOHYA

**KOHYA_ss** (`kohya-ss/sd-scripts`) es el framework utilizado para el fine-tuning. Proporciona:

-   Implementaci√≥n optimizada de fine-tuning para Stable Diffusion XL
-   Gesti√≥n avanzada de datasets con Aspect Ratio Bucketing
-   Configuraci√≥n granular de par√°metros de entrenamiento
-   Integraci√≥n con TensorBoard y W&B para monitoreo
-   Soporte para m√∫ltiples optimizadores y schedulers de learning rate
-   Fine-tuning selectivo de componentes (U-Net, Text Encoder)

---

## üìä Dataset y Preparaci√≥n de Datos

### Estructura del Dataset

El dataset utilizado para el fine-tuning consta de:

-   **N√∫mero de im√°genes:** 1486 im√°genes √∫nicas
-   **Resoluci√≥n:** 1024√ó1024 p√≠xeles
-   **Formato de imagen:** RGB (3 canales)
-   **Contenido:** Personajes distintos de Fortnite
-   **Formato de captions:** Archivos `.txt` asociados a cada imagen (mismo nombre base)

**Caracter√≠sticas del dataset:**

-   Im√°genes de personajes de Fortnite procesadas desde assets originales
-   Resoluci√≥n nativa de SDXL (1024√ó1024), √≥ptima para calidad y eficiencia
-   Cada imagen tiene un caption descriptivo asociado en formato texto plano
-   Dataset diverso que cubre diferentes tipos de personajes y outfits de Fortnite

**‚ö†Ô∏è NOTA:** La siguiente informaci√≥n debe extraerse de los archivos JSON de configuraci√≥n de entrenamiento:

-   N√∫mero de repeats por imagen utilizado en cada checkpoint
-   Uso de im√°genes de regularizaci√≥n (si aplica)
-   Estructura espec√≠fica de los captions (convenciones de etiquetado)

### Procesamiento de Datos

**Pipeline de preparaci√≥n:**

1. **Obtenci√≥n de datos:** Im√°genes de personajes de Fortnite desde assets originales
2. **Preprocesamiento:** Redimensionamiento y normalizaci√≥n a 1024√ó1024 p√≠xeles
3. **Captioning:** Generaci√≥n de archivos `.txt` con descripciones de cada personaje
4. **Validaci√≥n:** Verificaci√≥n de correspondencia entre im√°genes y captions

**Caracter√≠sticas t√©cnicas:**

-   Resoluci√≥n fija 1024√ó1024 (sin Aspect Ratio Bucketing necesario al ser resoluci√≥n uniforme)
-   Formato RGB est√°ndar (3 canales de color)
-   Captions en formato texto plano (`.txt`)

### Captioning

Los captions para fine-tuning incluyen:

-   Descripci√≥n de caracter√≠sticas visuales clave del personaje
-   Tags de estilo Fortnite
-   Anatom√≠a y estructura del personaje
-   Elementos de outfit y accesorios
-   Caracter√≠sticas distintivas que permiten al modelo aprender el estilo visual de Fortnite

---

## üéØ Estrategia de Fine-tuning

### Pipeline Completo

```
SDXL Base 1.0
    ‚Üì
Fine-tuning Iterativo
    ‚îú‚îÄ‚îÄ humanoid_02 (experimento inicial)
    ‚îú‚îÄ‚îÄ humanoid_03 (ajuste de hiperpar√°metros)
    ‚îú‚îÄ‚îÄ humanoid_04 (optimizaci√≥n)
    ‚îú‚îÄ‚îÄ humanoid_05 ‚úÖ (seleccionado como modelo final)
    ‚îú‚îÄ‚îÄ humanoid_06 (experimento adicional)
    ‚îî‚îÄ‚îÄ humanoid_07 (experimento adicional)
    ‚Üì
Modelo Base para LoRAs Especializados
```

### Par√°metros de Entrenamiento

**‚ö†Ô∏è NOTA:** Los hiperpar√°metros espec√≠ficos deben extraerse de los archivos JSON de configuraci√≥n de entrenamiento. La siguiente tabla muestra par√°metros t√≠picos para fine-tuning SDXL, pero **deben verificarse con los archivos de configuraci√≥n reales**.

| Par√°metro                  | Valor T√≠pico (SDXL Fine-tuning) | Justificaci√≥n                                             |
| -------------------------- | ------------------------------- | --------------------------------------------------------- |
| **Resoluci√≥n**             | 1024√ó1024                       | Resoluci√≥n nativa de SDXL, √≥ptima para calidad            |
| **Optimizer**              | AdamW8bit                       | Balance entre precisi√≥n y uso de memoria                  |
| **LR Scheduler**           | Cosine                          | Decaimiento suave del learning rate                       |
| **Mixed Precision**        | fp16                            | Reducci√≥n de memoria sin p√©rdida significativa de calidad |
| **Noise Offset**           | 0.05-0.1                        | Mejora contraste y saturaci√≥n de colores                  |
| **Caption Dropout**        | 0.05-0.1                        | Regularizaci√≥n para evitar overfitting a captions         |
| **Flip Augmentation**      | true                            | Aumento de datos mediante volteo horizontal               |
| **XFormers**               | true                            | Optimizaci√≥n de atenci√≥n para eficiencia                  |
| **Aspect Ratio Bucketing** | enabled                         | Permite diferentes aspect ratios dentro de buckets        |
| **Min Bucket Reso**        | 512                             | Resoluci√≥n m√≠nima para buckets                            |
| **Max Bucket Reso**        | 2048                            | Resoluci√≥n m√°xima para buckets                            |
| **Bucket Reso Steps**      | 64                              | Intervalo de resoluci√≥n para buckets                      |
| **Max Token Length**       | 225                             | Soporte para captions largos                              |
| **Clip Skip**              | 1                               | Uso de √∫ltima capa de CLIP (est√°ndar SDXL)                |
| **Loss Type**              | L2                              | Funci√≥n de p√©rdida est√°ndar                               |
| **Huber Schedule**         | SNR                             | Weighting basado en Signal-to-Noise Ratio                 |
| **Save Format**            | safetensors                     | Formato seguro y eficiente                                |

**‚ö†Ô∏è IMPORTANTE:** Los valores reales de los siguientes par√°metros **DEBEN extraerse de los archivos JSON de configuraci√≥n:**

-   Learning rate (U-Net)
-   Learning rate (Text Encoder)
-   Batch size
-   Gradient accumulation steps
-   Epochs / Total steps
-   Entrenamiento del Text Encoder (habilitado/deshabilitado, porcentaje de entrenamiento)
-   Regularizaciones espec√≠ficas (noise offset exacto, caption dropout exacto)

---

## üî¨ Proceso Iterativo de Fine-tuning

### Evoluci√≥n de Experimentos

Se observan m√∫ltiples checkpoints (`humanoid_02` a `humanoid_07`), indicando un proceso iterativo de experimentaci√≥n. Sin acceso a los archivos JSON de configuraci√≥n, no es posible documentar los cambios espec√≠ficos entre iteraciones.

**Informaci√≥n requerida de los archivos JSON:**

Para cada checkpoint (`humanoid_02` a `humanoid_07`), se necesita extraer:

1. **Hiperpar√°metros de entrenamiento:**

    - Learning rate (U-Net)
    - Learning rate (Text Encoder)
    - Batch size
    - Gradient accumulation steps
    - Epochs
    - Total steps

2. **Configuraci√≥n del dataset:**

    - N√∫mero de im√°genes
    - Repeats por imagen
    - Resoluci√≥n de entrenamiento

3. **Regularizaciones:**

    - Noise offset
    - Caption dropout rate
    - Otras t√©cnicas de regularizaci√≥n aplicadas

4. **Problemas detectados y soluciones:**

    - Overfitting
    - P√©rdida de identidad Fortnite
    - Incoherencia visual
    - Otros problemas observados

5. **Justificaci√≥n de cambios:**
    - Por qu√© se modificaron ciertos hiperpar√°metros
    - Qu√© problemas se buscaban corregir
    - C√≥mo las decisiones afectaron la calidad del modelo

### Metodolog√≠a de Evaluaci√≥n

La evaluaci√≥n de cada iteraci√≥n se realiz√≥ mediante:

1. **Generaci√≥n de muestras durante entrenamiento:** Cada epoch o conjunto de steps generaba im√°genes de prueba con prompts est√°ndar
2. **An√°lisis visual cualitativo:**
    - Coherencia con estilo Fortnite
    - Calidad anat√≥mica
    - Presencia de artefactos o deformaciones
    - Fidelidad a caracter√≠sticas visuales de Fortnite
3. **Detecci√≥n de problemas:**
    - **Overfitting:** Generaciones demasiado similares a im√°genes de entrenamiento
    - **Underfitting:** Falta de caracter√≠sticas distintivas de Fortnite
    - **P√©rdida de identidad Fortnite:** Desviaci√≥n excesiva del estilo base
    - **Ruido estil√≠stico:** Inconsistencias visuales entre generaciones

---

## üìà Selecci√≥n del Modelo Final

### Modelo Seleccionado: `humanoid_05`

**Justificaci√≥n de la selecci√≥n:**

El modelo `humanoid_05` fue seleccionado como modelo base final para los entrenamientos LoRA posteriores. Esta selecci√≥n se bas√≥ en:

1. **Balance √≥ptimo:** Equilibrio entre fidelidad al estilo Fortnite y capacidad de generalizaci√≥n
2. **Estabilidad:** Comportamiento estable en generaciones de prueba
3. **Base para LoRAs:** Capacidad demostrada de servir como base s√≥lida para especializaciones tem√°ticas mediante LoRAs

**‚ö†Ô∏è NOTA:** La justificaci√≥n detallada y los par√°metros espec√≠ficos de entrenamiento de `humanoid_05` deben extraerse de los archivos JSON de configuraci√≥n correspondientes.

### Caracter√≠sticas del Modelo Final

El modelo `humanoid_05` aprendi√≥ una distribuci√≥n visual que captura:

1. **Estilo Fortnite:**

    - Proporciones caracter√≠sticas de personajes
    - Iluminaci√≥n y sombreado distintivos
    - Texturas y materiales del juego
    - Anatom√≠a coherente con el arte de Fortnite

2. **Coherencia de outfit:**

    - Generaci√≥n coherente de prendas y accesorios
    - Integraci√≥n adecuada de elementos del outfit
    - Mantenimiento de estilo consistente

3. **Base para especializaci√≥n:**
    - Capacidad de servir como base para LoRAs tem√°ticos
    - Preservaci√≥n de caracter√≠sticas generales mientras permite especializaci√≥n

### Uso Posterior

Este modelo base se utiliza como punto de partida para todos los entrenamientos LoRA especializados documentados en `3.LoRAs/README.md`. Los LoRAs act√∫an como adaptadores que modulan el comportamiento del modelo base hacia categor√≠as tem√°ticas espec√≠ficas (Animal, Food, Robots, Star Wars, Fuzzy Bear) sin comprometer la identidad base establecida por el fine-tuning.

---

## ‚ö†Ô∏è Limitaciones y Trabajo Futuro

### Limitaciones Identificadas

1. **Documentaci√≥n incompleta:** Los archivos JSON de configuraci√≥n de entrenamiento no est√°n disponibles en la estructura de directorios actual, limitando la documentaci√≥n precisa de hiperpar√°metros y decisiones de ingenier√≠a.

2. **Dependencia del dataset:** La calidad del modelo final depende cr√≠ticamente de la calidad y diversidad del dataset de entrenamiento.

3. **Recursos computacionales:** El fine-tuning completo requiere recursos significativos (GPU con VRAM suficiente) y tiempo de entrenamiento extenso.

### Trabajo Futuro

1. **Documentaci√≥n completa:** Recuperar y documentar los archivos JSON de configuraci√≥n de entrenamiento para cada checkpoint experimental.

2. **An√°lisis comparativo:** Realizar an√°lisis comparativo detallado entre los diferentes checkpoints (`humanoid_02` a `humanoid_07`) para entender la evoluci√≥n del proceso.

3. **M√©tricas cuantitativas:** Implementar m√©tricas objetivas (FID, CLIP Score) adem√°s de evaluaci√≥n cualitativa para futuros fine-tunings.

4. **Optimizaci√≥n de hiperpar√°metros:** Automatizar b√∫squeda de hiperpar√°metros √≥ptimos mediante t√©cnicas de optimizaci√≥n bayesiana o grid search sistem√°tico.

5. **Expansi√≥n del dataset:** Evaluar el impacto de expandir el dataset de entrenamiento en la calidad y generalizaci√≥n del modelo.

---

## üìö Referencias T√©cnicas

-   **KOHYA_ss:** [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts)
-   **Stable Diffusion XL:** Stability AI - [Hugging Face](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)
-   **Fine-tuning Techniques:** Documentaci√≥n de KOHYA sobre fine-tuning de modelos completos
-   **Aspect Ratio Bucketing:** NovelAI implementation

---

## üìù Notas de Implementaci√≥n

**‚ö†Ô∏è NOTA:** La siguiente informaci√≥n debe completarse con datos de los archivos JSON de configuraci√≥n:

-   **Hardware utilizado:** [A extraer de archivos JSON]
-   **Tiempo de entrenamiento:** [A extraer de archivos JSON]
-   **Framework:** KOHYA_ss con soporte para SDXL
-   **Formato de salida:** SafeTensors (fp16)

---

## üîç Informaci√≥n Requerida para Completar Documentaci√≥n

Para completar esta documentaci√≥n con precisi√≥n t√©cnica, se requieren los siguientes archivos JSON de configuraci√≥n de entrenamiento de KOHYA:

1. **Archivos de configuraci√≥n por checkpoint:**

    - `humanoid_02_*.json` (o equivalente)
    - `humanoid_03_*.json`
    - `humanoid_04_*.json`
    - `humanoid_05_*.json` ‚úÖ (checkpoint seleccionado)
    - `humanoid_06_*.json`
    - `humanoid_07_*.json`

2. **Informaci√≥n a extraer de cada archivo:**

    - Modelo base utilizado
    - Resoluci√≥n de entrenamiento
    - Batch size
    - Gradient accumulation steps
    - Learning rate (U-Net)
    - Learning rate (Text Encoder)
    - Epochs / Total steps
    - Optimizador
    - Scheduler de learning rate
    - Entrenamiento del Text Encoder (habilitado/deshabilitado, porcentaje)
    - Regularizaciones (noise offset, caption dropout, etc.)
    - Configuraci√≥n del dataset (n√∫mero de im√°genes, repeats, etc.)

3. **Logs de entrenamiento (opcional pero recomendado):**
    - P√©rdidas durante entrenamiento
    - Im√°genes de muestra generadas durante entrenamiento
    - Observaciones y problemas detectados

---

**Autores:** Odreman Ferrer y Sergio Valdueza - TFM Deep Learning MIOTI  
**Licencia:** CC BY-NC-SA 4.0  
**√öltima actualizaci√≥n:** Diciembre 2025

**Estado del documento:** ‚ö†Ô∏è **INCOMPLETO** - Requiere acceso a archivos JSON de configuraci√≥n de entrenamiento para completar informaci√≥n t√©cnica precisa.
