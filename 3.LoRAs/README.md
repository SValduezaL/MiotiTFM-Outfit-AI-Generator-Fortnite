# Entrenamiento de LoRAs Especializados - TFM Skin AI Gen Fortnite

## üìã Overview del Proyecto

Este proyecto de Fin de M√°ster (TFM) tiene como objetivo la generaci√≥n de im√°genes de outfits de Fortnite mediante Inteligencia Artificial, utilizando una estrategia de fine-tuning inicial seguida de entrenamientos LoRA especializados para homogeneizar y controlar estilos tem√°ticos espec√≠ficos.

### Contexto Acad√©mico

**Problema abordado:** Control estil√≠stico y coherencia visual en la generaci√≥n de outfits de Fortnite mediante modelos generativos. El desaf√≠o principal radica en mantener la identidad visual caracter√≠stica de Fortnite mientras se especializa en diferentes categor√≠as tem√°ticas (animales, comida, robots, Star Wars, Fuzzy Bear).

**Soluci√≥n propuesta:** Arquitectura h√≠brida que combina fine-tuning del modelo base SDXL sobre datos de Fortnite, seguido de entrenamientos LoRA especializados por categor√≠a tem√°tica. Esta aproximaci√≥n permite mantener la coherencia del estilo base mientras se a√±ade especializaci√≥n estil√≠stica mediante adaptadores ligeros.

---

## üèóÔ∏è Arquitectura y Enfoque General

### Modelo Base

Todos los LoRAs se entrenan sobre el modelo fine-tuned **`v1x0_fortnite_humanoid_sdxl1_vae_fix-000005`**, que a su vez fue entrenado sobre **Stable Diffusion XL Base 1.0** (`sd_xl_base_1.0.safetensors`).

**Justificaci√≥n del enfoque Fine-tuning + LoRA:**

1. **Fine-tuning inicial:** Establece la base estil√≠stica de Fortnite, capturando caracter√≠sticas generales del arte del juego (proporciones, iluminaci√≥n, texturas, anatom√≠a).
2. **LoRAs especializados:** Permiten especializaci√≥n tem√°tica sin comprometer la identidad base. Cada LoRA act√∫a como un adaptador que modula el comportamiento del modelo base hacia una categor√≠a espec√≠fica.
3. **Ventajas t√©cnicas:**
   - **Eficiencia:** Los LoRAs (~10-50MB) son mucho m√°s ligeros que reentrenar el modelo completo (~7GB).
   - **Modularidad:** Cada categor√≠a tem√°tica puede actualizarse independientemente.
   - **Combinabilidad:** M√∫ltiples LoRAs pueden combinarse para estilos h√≠bridos.
   - **Preservaci√≥n:** El modelo base mantiene su capacidad de generar personajes humanos est√°ndar.

### Rol de KOHYA

**KOHYA_ss** (`kohya-ss/sd-scripts`) es el framework utilizado para el entrenamiento de LoRAs. Proporciona:

- Implementaci√≥n optimizada de LoRA para Stable Diffusion XL
- Gesti√≥n avanzada de datasets con Aspect Ratio Bucketing
- Configuraci√≥n granular de par√°metros de entrenamiento
- Integraci√≥n con TensorBoard y W&B para monitoreo
- Soporte para m√∫ltiples optimizadores y schedulers de learning rate

---

## üìä Dataset y Preparaci√≥n de Datos

### Estructura de Datasets

Cada LoRA se entren√≥ con datasets espec√≠ficos ubicados en `1.Datasets LoRAs/`:

| LoRA | Im√°genes | Resoluci√≥n | Formato Captions |
|------|----------|------------|------------------|
| **Animal** | 42 | 1024√ó1024 | `.txt` |
| **Food** | 27 | 1024√ó1024 | `.txt` |
| **FuzzyBear** | 8 | 1024√ó1024 | `.txt` |
| **Robots** | 15 | 1024√ó1024 | `.txt` |
| **StarWars** | 19 | 1024√ó1024 | `.txt` |

**Caracter√≠sticas del dataset:**
- Im√°genes procesadas desde assets originales de Fortnite
- Captions manuales con etiquetas descriptivas espec√≠ficas
- Formato: imagen `.png` + caption `.txt` con mismo nombre base
- Sin regularizaci√≥n expl√≠cita (no se utilizaron im√°genes de regularizaci√≥n)

### Captioning

Los captions fueron creados manualmente siguiendo convenciones espec√≠ficas:
- Inclusi√≥n de triggers tem√°ticos (ej: `fortnite_animal_character`)
- Descripci√≥n de caracter√≠sticas visuales clave
- Tags de calidad y estilo Fortnite
- Anatom√≠a y estructura del personaje

---

## üéØ Estrategia de Entrenamiento

### Pipeline Completo

```
SDXL Base 1.0
    ‚Üì
Fine-tuning (v1x0_fortnite_humanoid_sdxl1_vae_fix-000005)
    ‚Üì
LoRA Animal ‚îÄ‚îÄ‚îê
LoRA Food ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
LoRA FuzzyBear‚îú‚îÄ‚îÄ‚ñ∫ Inferencia con ComfyUI
LoRA Robots ‚îÄ‚îÄ‚î§
LoRA StarWars ‚îÄ‚îò
```

### Par√°metros Comunes de Entrenamiento

Todos los entrenamientos comparten la siguiente configuraci√≥n base:

| Par√°metro | Valor | Justificaci√≥n |
|-----------|-------|---------------|
| **Resoluci√≥n** | 1024√ó1024 | Resoluci√≥n nativa de SDXL, √≥ptima para calidad |
| **Optimizer** | AdamW8bit | Balance entre precisi√≥n y uso de memoria |
| **LR Scheduler** | Cosine | Decaimiento suave del learning rate |
| **Mixed Precision** | fp16 | Reducci√≥n de memoria sin p√©rdida significativa de calidad |
| **Noise Offset** | 0.05 | Mejora contraste y saturaci√≥n de colores |
| **Caption Dropout** | 0.1 | Regularizaci√≥n para evitar overfitting a captions |
| **Flip Augmentation** | true | Aumento de datos mediante volteo horizontal |
| **XFormers** | true | Optimizaci√≥n de atenci√≥n para eficiencia |
| **Aspect Ratio Bucketing** | enabled | Permite diferentes aspect ratios dentro de buckets |
| **Min Bucket Reso** | 512 | Resoluci√≥n m√≠nima para buckets |
| **Max Bucket Reso** | 2048 | Resoluci√≥n m√°xima para buckets (2048 para mayor√≠a, 1024 para StarWars) |
| **Bucket Reso Steps** | 64 | Intervalo de resoluci√≥n para buckets |
| **Max Token Length** | 225 | Soporte para captions largos |
| **Clip Skip** | 1 | Uso de √∫ltima capa de CLIP (est√°ndar SDXL) |
| **Loss Type** | L2 | Funci√≥n de p√©rdida est√°ndar |
| **Huber Schedule** | SNR | Weighting basado en Signal-to-Noise Ratio |
| **Save Format** | safetensors | Formato seguro y eficiente |

---

## üî¨ Entrenamiento de LoRAs con KOHYA

### 1. LoRA Animal

**Versi√≥n final seleccionada:** `v3`

#### Evoluci√≥n de Par√°metros

| Versi√≥n | Epochs | Steps | Batch | Rank | Alpha | LR (U-Net) | LR (Text Encoder) | Observaciones |
|---------|--------|-------|-------|------|-------|------------|-------------------|--------------|
| **v1** | 20 | 4200 | 4 | 16 | 8 | 8e-5 | 4e-5 | Entrenamiento inicial, 20 repeats |
| **v2** | 40 | 4200 | 4 | 16 | 8 | 8e-5 | 4e-5 | Aumento de epochs para mayor convergencia, 10 repeats |
| **v3** ‚úÖ | 15 | 4725 | 4 | 16 | 8 | 8e-5 | 4e-5 | Reducci√≥n de epochs, aumento de steps (30 repeats) |

**Par√°metros finales (v3):**
- **Dataset:** 42 im√°genes, 30 repeats
- **Batch Size:** 4
- **Epochs:** 15
- **Total Steps:** 4725
- **Network Rank (Dimension):** 16
- **Network Alpha:** 8 (ratio efectivo: 0.5)
- **Learning Rate (U-Net):** 8e-5
- **Learning Rate (Text Encoder):** 4e-5 (50% del U-Net)
- **Max Bucket Reso:** 2048

**Justificaci√≥n de la selecci√≥n:**
- Balance √≥ptimo entre convergencia y generalizaci√≥n
- Ratio alpha/rank de 0.5 proporciona suficiente capacidad sin overfitting
- Learning rate conservador (8e-5) evita inestabilidad
- 15 epochs con 30 repeats proporciona exposici√≥n suficiente sin memorizaci√≥n

**Problemas detectados y soluciones:**
- **v1 ‚Üí v2:** Overfitting temprano detectado ‚Üí Aumento de epochs con menos repeats para mejor generalizaci√≥n
- **v2 ‚Üí v3:** P√©rdida de identidad Fortnite en algunas generaciones ‚Üí Reducci√≥n de epochs, aumento de repeats para mayor exposici√≥n por imagen

---

### 2. LoRA Food

**Versi√≥n final seleccionada:** `v8`

#### Evoluci√≥n de Par√°metros

| Versi√≥n | Epochs | Steps | Batch | Rank | Alpha | LR (U-Net) | LR (Text Encoder) | Observaciones |
|---------|--------|-------|-------|------|-------|------------|-------------------|--------------|
| **v1** | 12 | 6480 | 2 | 32 | 16 | 1e-4 | 5e-5 | Rank alto, learning rate est√°ndar |
| **v2** | 20 | 4050 | 4 | 8 | 4 | 1e-4 | 5e-5 | Reducci√≥n dr√°stica de rank |
| **v3** | 20 | 4050 | 4 | 32 | 16 | 1e-4 | 5e-5 | Vuelta a rank alto |
| **v4** | 40 | 3240 | 4 | 8 | 4 | 1.5e-5 | 5e-5 | LR muy bajo, rank bajo |
| **v5** | 40 | 3240 | 4 | 16 | 8 | 1.5e-5 | 5e-5 | Aumento de rank, LR bajo |
| **v6** | 40 | 3240 | 4 | 8 | 4 | 5e-5 | 5e-5 | LR intermedio |
| **v7** | 40 | 3240 | 4 | 8 | 4 | 5e-4 | 5e-5 | LR muy alto (experimental) |
| **v8** ‚úÖ | 30 | 4050 | 4 | 16 | 8 | 8e-5 | 4e-5 | Configuraci√≥n final balanceada |
| **v9** | 10 | 4050 | 2 | 16 | 8 | 8e-5 | 4e-5 | Batch reducido, epochs m√≠nimos |

**Par√°metros finales (v8):**
- **Dataset:** 27 im√°genes, 20 repeats
- **Batch Size:** 4
- **Epochs:** 30
- **Total Steps:** 4050
- **Network Rank (Dimension):** 16
- **Network Alpha:** 8 (ratio efectivo: 0.5)
- **Learning Rate (U-Net):** 8e-5
- **Learning Rate (Text Encoder):** 4e-5
- **Max Bucket Reso:** 2048

**Justificaci√≥n de la selecci√≥n:**
- Configuraci√≥n que balancea capacidad (rank 16) con estabilidad (LR 8e-5)
- 30 epochs proporcionan convergencia adecuada sin overfitting
- Ratio alpha/rank de 0.5 mantiene el efecto del LoRA controlado

**Problemas detectados y soluciones:**
- **v1 ‚Üí v2:** Rank 32 causaba overfitting y artefactos ‚Üí Reducci√≥n a rank 8
- **v2 ‚Üí v3:** Rank 8 insuficiente para capturar detalles complejos de comida ‚Üí Vuelta a rank 32
- **v3 ‚Üí v4-v7:** Experimentaci√≥n con learning rates extremos ‚Üí Inestabilidad o convergencia lenta
- **v4-v7 ‚Üí v8:** Configuraci√≥n balanceada con rank 16 y LR 8e-5 ‚Üí Resultados estables y coherentes
- **v8 ‚Üí v9:** Prueba con menos epochs ‚Üí Insuficiente convergencia, se mantiene v8

---

### 3. LoRA FuzzyBear

**Versi√≥n final seleccionada:** `v5`

#### Evoluci√≥n de Par√°metros

| Versi√≥n | Epochs | Steps | Batch | Rank | Alpha | LR (U-Net) | LR (Text Encoder) | Observaciones |
|---------|--------|-------|-------|------|-------|------------|-------------------|--------------|
| **v1** | 20 | 4000 | 2 | 32 | 16 | 1e-4 | 5e-5 | Rank alto inicial |
| **v2** | 10 | 2000 | 2 | 32 | 16 | 1e-4 | 5e-5 | Reducci√≥n de epochs |
| **v3** | 15 | 3000 | 2 | 32 | 16 | 1e-4 | 5e-5 | Epochs intermedios |
| **v4** | 20 | 4000 | 2 | 16 | 16 | 1e-4 | 5e-5 | Reducci√≥n de rank, alpha igual |
| **v5** ‚úÖ | 20 | 4000 | 2 | 8 | 4 | 1e-4 | 5e-5 | Rank y alpha reducidos |

**Par√°metros finales (v5):**
- **Dataset:** 8 im√°genes, 50 repeats
- **Batch Size:** 2
- **Epochs:** 20
- **Total Steps:** 4000
- **Network Rank (Dimension):** 8
- **Network Alpha:** 4 (ratio efectivo: 0.5)
- **Learning Rate (U-Net):** 1e-4
- **Learning Rate (Text Encoder):** 5e-5
- **Max Bucket Reso:** 2048

**Justificaci√≥n de la selecci√≥n:**
- Dataset peque√±o (8 im√°genes) requiere rank bajo para evitar overfitting
- 50 repeats proporcionan exposici√≥n suficiente pese al tama√±o reducido del dataset
- Rank 8 con alpha 4 mantiene capacidad suficiente para el estilo FuzzyBear
- Learning rate est√°ndar (1e-4) funciona bien con batch size 2

**Problemas detectados y soluciones:**
- **v1-v3:** Rank 32 causaba overfitting severo con dataset peque√±o ‚Üí Reducci√≥n progresiva de rank
- **v4:** Rank 16 con alpha 16 (ratio 1.0) ‚Üí Efecto del LoRA demasiado fuerte, p√©rdida de coherencia
- **v4 ‚Üí v5:** Reducci√≥n a rank 8 y alpha 4 ‚Üí Balance √≥ptimo para dataset peque√±o

---

### 4. LoRA Robots

**Versi√≥n final seleccionada:** `v2`

#### Evoluci√≥n de Par√°metros

| Versi√≥n | Epochs | Steps | Batch | Rank | Alpha | LR (U-Net) | LR (Text Encoder) | Observaciones |
|---------|--------|-------|-------|------|-------|------------|-------------------|--------------|
| **v1** | 25 | 3750 | 4 | 16 | 8 | 1e-4 | 5e-5 | Configuraci√≥n inicial est√°ndar |
| **v2** ‚úÖ | 15 | 4500 | 2 | 8 | 4 | 1e-4 | 5e-5 | Reducci√≥n de rank y batch |

**Par√°metros finales (v2):**
- **Dataset:** 15 im√°genes, 40 repeats
- **Batch Size:** 2
- **Epochs:** 15
- **Total Steps:** 4500
- **Network Rank (Dimension):** 8
- **Network Alpha:** 4 (ratio efectivo: 0.5)
- **Learning Rate (U-Net):** 1e-4
- **Learning Rate (Text Encoder):** 5e-5
- **Max Bucket Reso:** 2048

**Justificaci√≥n de la selecci√≥n:**
- Dataset mediano (15 im√°genes) se beneficia de rank bajo para evitar overfitting
- Batch size 2 permite mayor granularidad en el entrenamiento
- 15 epochs con 40 repeats proporcionan exposici√≥n adecuada
- Rank 8 es suficiente para capturar caracter√≠sticas rob√≥ticas sin memorizar detalles espec√≠ficos

**Problemas detectados y soluciones:**
- **v1:** Rank 16 con batch 4 ‚Üí Overfitting a detalles espec√≠ficos de robots del dataset
- **v1 ‚Üí v2:** Reducci√≥n a rank 8 y batch 2 ‚Üí Mayor generalizaci√≥n, mejor coherencia estil√≠stica

---

### 5. LoRA StarWars

**Versi√≥n final seleccionada:** `v1`

#### Par√°metros Finales

- **Dataset:** 19 im√°genes, 40 repeats
- **Batch Size:** 4
- **Epochs:** 20
- **Total Steps:** 3800
- **Network Rank (Dimension):** 16
- **Network Alpha:** 16 (ratio efectivo: 1.0)
- **Learning Rate (U-Net):** 1e-4
- **Learning Rate (Text Encoder):** 5e-5
- **Max Bucket Reso:** 1024 (diferente a otros LoRAs)

**Justificaci√≥n de la configuraci√≥n:**
- √önico LoRA con alpha igual a rank (ratio 1.0), maximizando el efecto del adaptador
- Max bucket reso de 1024 (vs 2048 en otros) para mantener coherencia con el estilo Star Wars
- Rank 16 proporciona capacidad suficiente para detalles caracter√≠sticos (armaduras, cascos, etc.)
- 20 epochs con 40 repeats aseguran convergencia adecuada

**Nota:** Este LoRA fue entrenado en una sola iteraci√≥n, sin necesidad de ajustes adicionales debido a la configuraci√≥n inicial √≥ptima.

---

## üìà An√°lisis Comparativo de Par√°metros

### Network Rank (Dimension)

| LoRA | Rank Final | Justificaci√≥n |
|------|-----------|--------------|
| Animal | 16 | Dataset grande (42), necesita capacidad para detalles animales |
| Food | 16 | Dataset mediano (27), balance entre capacidad y generalizaci√≥n |
| FuzzyBear | 8 | Dataset peque√±o (8), rank bajo previene overfitting |
| Robots | 8 | Dataset mediano (15), rank bajo mejora generalizaci√≥n |
| StarWars | 16 | Dataset mediano (19), necesita capacidad para detalles complejos |

### Network Alpha / Rank Ratio

| LoRA | Alpha | Rank | Ratio | Efecto |
|------|-------|------|-------|--------|
| Animal | 8 | 16 | 0.5 | Efecto moderado, balanceado |
| Food | 8 | 16 | 0.5 | Efecto moderado, balanceado |
| FuzzyBear | 4 | 8 | 0.5 | Efecto moderado, balanceado |
| Robots | 4 | 8 | 0.5 | Efecto moderado, balanceado |
| StarWars | 16 | 16 | 1.0 | Efecto m√°ximo, adaptador completo |

**Observaci√≥n:** Todos los LoRAs excepto StarWars utilizan ratio 0.5, que es un est√°ndar com√∫n. StarWars utiliza ratio 1.0 para maximizar el impacto del adaptador, posiblemente debido a la necesidad de capturar caracter√≠sticas muy espec√≠ficas del universo Star Wars.

### Learning Rate

| LoRA | LR U-Net | LR Text Encoder | Ratio TE/U-Net |
|------|----------|-----------------|----------------|
| Animal | 8e-5 | 4e-5 | 0.5 |
| Food | 8e-5 | 4e-5 | 0.5 |
| FuzzyBear | 1e-4 | 5e-5 | 0.5 |
| Robots | 1e-4 | 5e-5 | 0.5 |
| StarWars | 1e-4 | 5e-5 | 0.5 |

**Patr√≥n observado:**
- Animal y Food utilizan LR m√°s conservador (8e-5) ‚Üí Mayor estabilidad
- FuzzyBear, Robots y StarWars utilizan LR est√°ndar (1e-4) ‚Üí Convergencia m√°s r√°pida
- Todos mantienen ratio Text Encoder / U-Net de 0.5 ‚Üí Text Encoder se entrena m√°s lentamente para evitar overfitting

---

## üéØ Selecci√≥n Final de Modelos

### Resumen de LoRAs Finales

| LoRA | Versi√≥n | Archivo | Tama√±o Dataset | Epochs | Steps | Rank | Alpha | LR |
|------|---------|--------|----------------|--------|-------|------|-------|-----|
| **Animal** | v3 | `FT_Humanoid_5e_vF_LoRA_Animal_v3-000012.safetensors` | 42 | 15 | 4725 | 16 | 8 | 8e-5 |
| **Food** | v8 | `FT_Humanoid_5e_vF_LoRA_Food_v8-000008.safetensors` | 27 | 30 | 4050 | 16 | 8 | 8e-5 |
| **FuzzyBear** | v5 | `FT_Humanoid_5e_vF_LoRA_FuzzyBear_v5-000020.safetensors` | 8 | 20 | 4000 | 8 | 4 | 1e-4 |
| **Robots** | v2 | `FT_Humanoid_5e_vF_LoRA_Robots_v2-000008.safetensors` | 15 | 15 | 4500 | 8 | 4 | 1e-4 |
| **StarWars** | v1 | `FT_Humanoid_5e_vF_LoRA_StarWars_v1-000013.safetensors` | 19 | 20 | 3800 | 16 | 16 | 1e-4 |

### Triggers por Categor√≠a

Cada LoRA utiliza triggers espec√≠ficos en los prompts para activar el estilo:

- **Animal:** `fortnite_animal_character, nice_hands, `
- **Food:** `fortnite_food_character, nice_hands, `
- **FuzzyBear:** `fortnite_fuzzy_bear_character, nice_hands, `
- **Robots:** `fortnite_robots_character, nice_hands, `
- **StarWars:** `fortnite_star_wars_character, nice_hands, `

### Diferencias Clave entre LoRAs

1. **Especializaci√≥n:**
   - **Animal y Food:** Rank 16, mayor capacidad para detalles complejos
   - **FuzzyBear y Robots:** Rank 8, enfoque en generalizaci√≥n sobre memorizaci√≥n
   - **StarWars:** Rank 16 con alpha 16, m√°ximo impacto del adaptador

2. **Robustez:**
   - **Animal:** Mayor robustez debido a dataset grande (42 im√°genes)
   - **FuzzyBear:** Menor robustez pero suficiente para dataset peque√±o (8 im√°genes)
   - **Food, Robots, StarWars:** Robustez intermedia

3. **Coherencia:**
   - Todos mantienen coherencia con el estilo base Fortnite
   - StarWars tiene mayor desviaci√≥n estil√≠stica permitida (alpha/rank = 1.0)
   - FuzzyBear y Robots priorizan coherencia sobre especializaci√≥n extrema

---

## üîç Proceso Iterativo y Ajustes

### Metodolog√≠a de Evaluaci√≥n

La evaluaci√≥n de cada iteraci√≥n se realiz√≥ mediante:

1. **Generaci√≥n de muestras durante entrenamiento:** Cada epoch generaba im√°genes de prueba con prompts est√°ndar
2. **An√°lisis visual cualitativo:**
   - Coherencia con estilo Fortnite
   - Calidad anat√≥mica
   - Presencia de artefactos o deformaciones
   - Fidelidad a la categor√≠a tem√°tica
3. **Detecci√≥n de problemas:**
   - **Overfitting:** Generaciones demasiado similares a im√°genes de entrenamiento
   - **Underfitting:** Falta de caracter√≠sticas tem√°ticas distintivas
   - **P√©rdida de identidad Fortnite:** Desviaci√≥n excesiva del estilo base
   - **Ruido estil√≠stico:** Inconsistencias visuales entre generaciones

### Ajustes Comunes Realizados

1. **Reducci√≥n de Rank:** Cuando se detectaba overfitting, se reduc√≠a el rank para limitar la capacidad del adaptador
2. **Ajuste de Learning Rate:** Learning rates muy altos causaban inestabilidad; muy bajos, convergencia lenta
3. **Modificaci√≥n de Epochs/Repeats:** Balance entre exposici√≥n suficiente y evitar memorizaci√≥n
4. **Cambio de Batch Size:** Batch m√°s peque√±os permiten mayor granularidad pero requieren m√°s epochs

---

## üìä Resultados y Ejemplos

Los LoRAs finales se utilizan en el sistema de generaci√≥n mediante ComfyUI, integrados en workflows espec√≠ficos que combinan:

- Modelo base fine-tuned: `v1x0_fortnite_humanoid_sdxl1_vae_fix-000005`
- LoRA especializado seg√∫n categor√≠a
- LoRA NiceHands para mejora de anatom√≠a de manos
- SDXL Refiner para post-procesamiento de alta calidad

Ejemplos de generaciones se encuentran en `4.Inferencias LoRAs seleccionados/`.

---

## ‚ö†Ô∏è Limitaciones y Trabajo Futuro

### Limitaciones Identificadas

1. **Tama√±o de datasets:** Algunos datasets (especialmente FuzzyBear con 8 im√°genes) son peque√±os y limitan la generalizaci√≥n
2. **Overfitting en detalles espec√≠ficos:** Algunos LoRAs tienden a memorizar caracter√≠sticas espec√≠ficas de im√°genes de entrenamiento
3. **Combinabilidad limitada:** Los LoRAs no est√°n optimizados para combinarse entre s√≠
4. **Dependencia del modelo base:** Cambios en el modelo base requieren reentrenamiento de LoRAs

### Trabajo Futuro

1. **Expansi√≥n de datasets:** Aumentar el tama√±o de datasets, especialmente para FuzzyBear y Robots
2. **Regularizaci√≥n expl√≠cita:** Incorporar im√°genes de regularizaci√≥n para mejorar generalizaci√≥n
3. **LoRAs combinables:** Investigar t√©cnicas para permitir combinaci√≥n de m√∫ltiples LoRAs
4. **Fine-tuning de triggers:** Optimizar triggers mediante an√°lisis de activaci√≥n
5. **M√©tricas cuantitativas:** Implementar m√©tricas objetivas (FID, CLIP Score) adem√°s de evaluaci√≥n cualitativa
6. **Hiperpar√°metros adaptativos:** Automatizar b√∫squeda de hiperpar√°metros seg√∫n tama√±o y caracter√≠sticas del dataset

---

## üìö Referencias T√©cnicas

- **KOHYA_ss:** [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts)
- **LoRA Paper:** "LoRA: Low-Rank Adaptation of Large Language Models" (Hu et al., 2021)
- **Stable Diffusion XL:** Stability AI
- **Aspect Ratio Bucketing:** NovelAI implementation

---

## üìù Notas de Implementaci√≥n

- **Hardware utilizado:** NVIDIA A100 (80GB VRAM) para mayor√≠a de entrenamientos, A100 (40GB VRAM) para algunos
- **Tiempo de entrenamiento:** Variable seg√∫n dataset y configuraci√≥n, t√≠picamente 2-6 horas por LoRA
- **Framework:** KOHYA_ss con soporte para SDXL
- **Formato de salida:** SafeTensors (fp16)

---

**Autores:** Odreman Ferrer y Sergio Valdueza - TFM Deep Learning MIOTI  
**Licencia:** CC BY-NC-SA 4.0  
**√öltima actualizaci√≥n:** Diciembre 2025

