# Pipeline de Preparaci√≥n de Datos - TFM Skin AI Generation Fortnite

Este directorio contiene el pipeline completo de preparaci√≥n de datos para el proyecto de generaci√≥n de skins de Fortnite mediante IA. Los notebooks y scripts est√°n organizados en orden secuencial seg√∫n el flujo de procesamiento.

## üìã √çndice

1. [Obtenci√≥n de Datos](#1-obtenci√≥n-de-datos)
2. [Limpieza de Im√°genes](#2-limpieza-de-im√°genes)
3. [Reducci√≥n de Tama√±o](#3-reducci√≥n-de-tama√±o)
4. [Aumento de Datos](#4-aumento-de-datos)
5. [Transformaci√≥n de Dimensiones](#5-transformaci√≥n-de-dimensiones)
6. [Generaci√≥n de Etiquetas](#6-generaci√≥n-de-etiquetas)
7. [Mejora de Etiquetas](#7-mejora-de-etiquetas)

---

## 1. Obtenci√≥n de Datos

### `0.1.get_items_from_api.ipynb`

**Objetivo:** Obtener los datos de los items cosm√©ticos de Fortnite desde la API oficial.

**Funcionalidad:**

-   Se conecta a la API de Fortnite (`fortniteapi.io`) utilizando la API key almacenada en variables de entorno
-   Extrae informaci√≥n de todos los items cosm√©ticos disponibles (skins, emotes, etc.)
-   Normaliza y estructura los datos JSON en DataFrames de pandas
-   Genera archivos CSV de salida:
    -   `items.csv`: Contiene todos los items cosm√©ticos con sus metadatos
    -   `emotes.csv`: Contiene informaci√≥n espec√≠fica de emotes
    -   `outfit.csv`: Contiene informaci√≥n de outfits/skins
    -   `outfits_with_details.csv`: Contiene informaci√≥n de los outfits con m√°s detalles
-   Descarga las im√°genes en 1024x1024 y 4 canales RGBA.

**Salidas:**

-   `items.csv`
-   `emotes.csv`
-   `outfit.csv`
-   `outfits_with_details.csv`
-   Carpeta `outfits_originales_1024_rgba` con las im√°genes originales de la API de Fortnite.

**Dependencias:**

-   API key de Fortnite (almacenada en `.env` como `FORTNITE_API_KEY`)
-   `pandas`, `requests`, `python-dotenv`

---

## 2. Limpieza de Im√°genes

### `0.2.1.data_cleaning.ipynb`

**Objetivo:** Preprocesar y limpiar las im√°genes originales de los personajes de Fortnite.

**Funcionalidad:**

-   **Entrada:** Im√°genes originales en formato RGBA (1024x1024 p√≠xeles) desde `outfits_originales_1024_rgba/`
-   **Procesamiento:**
    1. Limpieza de fondos: Elimina p√≠xeles semi-transparentes estableciendo un umbral de opacidad (200)
    2. Aislamiento del objeto principal: Detecta y extrae el contorno m√°s grande (el personaje principal)
    3. Eliminaci√≥n de artefactos: Remueve objetos secundarios y ruido
-   **Salidas:**
    -   `outfits_procesados_1024_rgba/`: Versiones procesadas manteniendo canal alfa
    -   `outfits_procesados_1024_rgb/`: Versiones procesadas sin canal alfa (RGB)

**Caracter√≠sticas t√©cnicas:**

-   Utiliza OpenCV para procesamiento de im√°genes
-   Detecta contornos para aislar el objeto principal
-   Aplica m√°scaras binarias para limpieza de fondos

---

## 3. Reducci√≥n de Tama√±o

### `0.2.3.size_reduction con PIL.py`

**Objetivo:** Reducir el tama√±o de las im√°genes procesadas usando PIL con antialiasing de alta calidad.

**Funcionalidad:**

-   **Entrada:** Im√°genes procesadas de 1024x1024 p√≠xeles desde `outfits_procesados_1024_rgb/`
-   **Procesamiento:**
    1. Reducci√≥n a 512x512 p√≠xeles usando filtro LANCZOS (alta calidad)
    2. Reducci√≥n adicional a 256x256 p√≠xeles desde la versi√≥n 512x512
-   **Salidas:**
    -   `outfits_procesados_512_rgb/`: Im√°genes de 512x512
    -   `outfits_procesados_256_rgb/`: Im√°genes de 256x256

**Ventajas:**

-   Filtro LANCZOS preserva mejor la nitidez durante el downscaling
-   Ideal para mantener calidad visual en datasets

### `0.2.3.size_reduction con CV2.py`

**Objetivo:** Alternativa al script anterior usando OpenCV para reducci√≥n de tama√±o.

**Funcionalidad:**

-   Similar al script PIL pero utiliza `cv2.INTER_AREA` para interpolaci√≥n
-   M√°s r√°pido que PIL pero con calidad ligeramente inferior
-   Mismas entradas y salidas que el script PIL

**Cu√°ndo usar:**

-   Cuando la velocidad es prioritaria sobre la calidad m√°xima
-   Para procesamiento en lotes grandes

---

## 4. Aumento de Datos

### `0.2.2.1.data_augmentation.ipynb`

**Objetivo:** Generar m√∫ltiples variaciones de cada imagen mediante t√©cnicas de data augmentation.

**Funcionalidad:**

-   **Entrada:** Im√°genes procesadas de 1024x1024 RGB desde `outfits_procesados_1024_rgb/`
-   **T√©cnicas aplicadas:**
    1. **Transformaciones de color:**
        - Ajuste de brillo y contraste aleatorio
        - Cambio de tono y saturaci√≥n
        - Desplazamiento RGB
    2. **Transformaciones geom√©tricas:**
        - Volteo horizontal
        - Rotaci√≥n, escala y traslaci√≥n
        - Detecci√≥n de personajes "grounded" (pegados al suelo) o "ceiled" (pegados al techo) para aplicar transformaciones espec√≠ficas
-   **Salidas:**
    -   `outfits_augmented_1024_rgb/`: M√∫ltiples variaciones de cada imagen original
    -   Genera aproximadamente 34 aumentaciones por imagen original (objetivo: 50,000 im√°genes totales)

**Caracter√≠sticas especiales:**

-   Detecta si el personaje est√° "grounded" o "ceiled" para aplicar transformaciones apropiadas
-   Descarta aumentaciones que resulten en personajes "ceiled"
-   Preserva el fondo negro durante las transformaciones

---

## 5. Transformaci√≥n de Dimensiones

### `0.2.2.2.data_transformation_256x512.ipynb`

**Objetivo:** Transformar im√°genes de 512x512 a formato 256x512 (aspecto vertical).

**Funcionalidad:**

-   **Entrada:** Im√°genes de 512x512 desde `outfits_procesados_512_rgb/`
-   **Procesamiento:**
    1. Detecci√≥n de m√°rgenes: Identifica las columnas con contenido visible
    2. Recorte inteligente: Elimina m√°rgenes laterales vac√≠os
    3. Redimensionamiento proporcional: Ajusta el ancho a 256 p√≠xeles manteniendo proporci√≥n
    4. Padding superior: A√±ade padding negro en la parte superior si la altura es menor a 512px
-   **Salidas:**
    -   `outfits_procesados_256x512_rgb/`: Im√°genes en formato 256x512

**Caracter√≠sticas t√©cnicas:**

-   Utiliza PIL con filtro LANCZOS para redimensionamiento de alta calidad
-   Detecta autom√°ticamente el √°rea visible para centrar el contenido
-   Asegura dimensiones finales exactas de 256x512

---

## 6. Generaci√≥n de Etiquetas

### `0.2.4.etiquetas.ipynb`

**Objetivo:** Generar etiquetas descriptivas para cada imagen del dataset.

**Funcionalidad:**

-   **Entrada:**
    -   Im√°genes procesadas desde `outfits_procesados_1024_rgb/`
    -   Datos del CSV (`outfits_with_details.csv`) con metadatos de los personajes
-   **Procesamiento:**
    1. **Generaci√≥n con BLIP:** Utiliza el modelo BLIP (Bootstrapping Language-Image Pre-training) para generar descripciones autom√°ticas de las im√°genes
    2. **Enriquecimiento con metadatos:** Combina las descripciones de BLIP con informaci√≥n del CSV:
        - Nombre del personaje
        - Nombre del set/colecci√≥n
        - Serie (Marvel, Star Wars, DC Comics, etc.)
    3. **Tags de estilo:** A√±ade tags espec√≠ficos de estilo Fortnite
    4. **Manejo de im√°genes no encontradas:** Para im√°genes sin match en el CSV, utiliza solo BLIP
-   **Salidas:**
    -   Archivos `.txt` con etiquetas para cada imagen en `tags/`
    -   Archivos `_store_tags.txt` con solo los tags del CSV en `tags_store/`

**Modelo utilizado:**

-   BLIP (Salesforce/blip-image-captioning-base) para generaci√≥n autom√°tica de descripciones

---

## 7. Mejora de Etiquetas

### `0.2.5.mejorar-etiquetas.ipynb`

**Objetivo:** Refinar y mejorar las etiquetas generadas usando inteligencia artificial avanzada.

**Funcionalidad:**

-   **Entrada:**
    -   Etiquetas generadas previamente (archivos `.txt`)
    -   Datos del CSV con informaci√≥n adicional (nombre, descripci√≥n, colaboraciones)
-   **Procesamiento:**
    1. Lee las etiquetas originales generadas por BLIP
    2. Utiliza Google Gemini API para:
        - Refinar y mejorar las descripciones
        - A√±adir contexto adicional basado en metadatos del CSV
        - Optimizar el formato y estructura de las etiquetas
    3. Genera versiones mejoradas de las etiquetas
-   **Salidas:**
    -   Archivos `.txt` mejorados en el directorio de salida

**Dependencias:**

-   Google Gemini API (almacenada en `.env` como `GOOGLE_GEMINI_API_KEY`)
-   `google-generativeai`, `pandas`

**Caracter√≠sticas:**

-   Procesamiento por lotes con logging
-   Manejo de errores y reintentos
-   Preserva informaci√≥n relevante mientras mejora la calidad descriptiva

---

## üîÑ Flujo de Procesamiento Completo

```
1. Obtener datos de API
   ‚îî‚îÄ> 0.1.get_items_from_api.ipynb
       ‚îî‚îÄ> Genera: items.csv, emotes.csv, outfit.csv, outfits_with_details.csv
       ‚îî‚îÄ> outfits_originales_1024_rgba/

2. Limpiar im√°genes originales
   ‚îî‚îÄ> 0.2.1.data_cleaning.ipynb
       ‚îî‚îÄ> outfits_originales_1024_rgba/
           ‚îî‚îÄ> outfits_procesados_1024_rgb/

3. Reducir tama√±o de im√°genes
   ‚îî‚îÄ> 0.2.3.size_reduction con PIL.py (o CV2.py)
       ‚îî‚îÄ> outfits_procesados_1024_rgb/
           ‚îî‚îÄ> outfits_procesados_512_rgb/
           ‚îî‚îÄ> outfits_procesados_256_rgb/

4. Aumentar datos
   ‚îî‚îÄ> 0.2.2.1.data_augmentation.ipynb
       ‚îî‚îÄ> outfits_procesados_1024_rgb/
           ‚îî‚îÄ> outfits_augmented_1024_rgb/

5. Transformar dimensiones
   ‚îî‚îÄ> 0.2.2.2.data_transformation_256x512.ipynb
       ‚îî‚îÄ> outfits_procesados_512_rgb/
           ‚îî‚îÄ> outfits_procesados_256x512_rgb/

6. Generar etiquetas
   ‚îî‚îÄ> 0.2.4.etiquetas.ipynb
       ‚îî‚îÄ> outfits_procesados_1024_rgb/ + outfits_with_details.csv
           ‚îî‚îÄ> tags/*.txt

7. Mejorar etiquetas
   ‚îî‚îÄ> 0.2.5.mejorar-etiquetas.ipynb
       ‚îî‚îÄ> tags/*.txt + outfits_with_details.csv
           ‚îî‚îÄ> tags mejorados
```

---

## üì¶ Dependencias Principales

-   **Procesamiento de im√°genes:** `opencv-python`, `Pillow`, `numpy`
-   **Aumento de datos:** `albumentations`
-   **Procesamiento de datos:** `pandas`
-   **APIs:** `requests`, `google-generativeai`
-   **IA/ML:** `transformers` (para BLIP)
-   **Utilidades:** `tqdm`, `python-dotenv`

---

## ‚öôÔ∏è Configuraci√≥n

Antes de ejecutar los notebooks, aseg√∫rate de:

1. **Configurar variables de entorno** en el archivo `.env` en la ra√≠z del proyecto:

    ```
    FORTNITE_API_KEY=tu_api_key_aqui
    GOOGLE_GEMINI_API_KEY=tu_api_key_aqui
    ```

2. **Verificar rutas de directorios** en cada notebook seg√∫n tu estructura de carpetas

3. **Instalar dependencias** desde `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```

---

## üìù Notas Importantes

-   Los notebooks est√°n dise√±ados para ejecutarse en orden secuencial
-   Algunos notebooks pueden tardar considerablemente (especialmente data augmentation y generaci√≥n de etiquetas)
-   Se recomienda verificar las salidas de cada paso antes de continuar al siguiente
-   Los scripts de reducci√≥n de tama√±o (PIL vs CV2) son alternativas entre s√≠, no es necesario ejecutar ambos

---

## üêõ Soluci√≥n de Problemas

-   **Error de API keys:** Verifica que el archivo `.env` est√© en la ra√≠z del proyecto y contenga las claves correctas
-   **Rutas no encontradas:** Ajusta las rutas de entrada/salida en cada notebook seg√∫n tu estructura de directorios
-   **Memoria insuficiente:** Para datasets grandes, considera procesar en lotes m√°s peque√±os
-   **Modelos no encontrados:** Los modelos de BLIP se descargan autom√°ticamente en la primera ejecuci√≥n

---

**√öltima actualizaci√≥n:** Dic2025
